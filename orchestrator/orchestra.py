import asyncio
import json
import logging
from enum import Enum
from common.kafka import get_kafka_producer, get_kafka_consumer
from prometheus_client import Counter, start_http_server
import pyfiglet
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from aiokafka.errors import KafkaTimeoutError
import redis.asyncio as aioredis

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
)
logger = logging.getLogger("orchestrator")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ascii_banner = pyfiglet.figlet_format("TTTS ORCHESTRATOR 0.0.3", font="slant")
print(ascii_banner)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# METRICS
orch_received = Counter("orchestrator_received_total", "Total transactions received from API")
orch_sent = Counter("orchestrator_sent_total", "Total transactions sent to worker")
orch_queued = Counter("orchestrator_queued_total", "Transactions queued due to active lock")
orch_confirmation_received = Counter("orchestrator_confirmation_received_total", "Total confirmations received")

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOPIC_API_TO_ORCH = "transaction-events"
TOPIC_CONFIRMATION = "transaction-confirmation"
SHARD_COUNT = 16

REDIS_URL = "redis://redis:6379"  # –∞–¥–∞–ø—Ç–∏—Ä—É–π –µ—Å–ª–∏ –Ω—É–∂–Ω–æ

MAX_PARALLEL_SENDS = 5000
send_semaphore = asyncio.Semaphore(MAX_PARALLEL_SENDS)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ACCOUNT STATE MACHINE

class AccountState(Enum):
    IDLE = "idle"
    BUSY = "busy"

def get_shard(account_id: str) -> int:
    return hash(account_id) % SHARD_COUNT

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@retry(
    stop=stop_after_attempt(5),
    wait=wait_exponential(multiplier=0.5),
    retry=retry_if_exception_type(KafkaTimeoutError)
)
async def send_with_retry(producer, topic, msg: bytes):
    async with send_semaphore:
        await producer.send(topic, msg)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def lock_accounts(redis, sender: str, receiver: str) -> bool:
    """–ü—ã—Ç–∞–µ–º—Å—è –∑–∞–Ω—è—Ç—å –∞–∫–∫–∞—É–Ω—Ç—ã."""
    try:
        pipe = redis.pipeline()
        pipe.setnx(f"lock:{sender}", "locked")
        pipe.setnx(f"lock:{receiver}", "locked")
        results = await pipe.execute()

        logger.info(f"üîí –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–ª–æ—á–∏—Ç—å –∞–∫–∫–∞—É–Ω—Ç—ã {sender} –∏ {receiver}: {'—É—Å–ø–µ—Ö' if all(results) else '–Ω–µ—É–¥–∞—á–∞'}")
        # –ï—Å–ª–∏ –æ–±–∞ –∞–∫–∫–∞—É–Ω—Ç–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–ª–æ—á–µ–Ω—ã ‚Äî —É—Å–ø–µ—Ö
        return all(results)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–µ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ {sender} –∏ {receiver}: {e}")
        return False

async def unlock_accounts(redis, sender: str, receiver: str):
    """–û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –∞–∫–∫–∞—É–Ω—Ç—ã."""
    try:
        await redis.delete(f"lock:{sender}", f"lock:{receiver}")
        logger.info(f"üîì –ê–∫–∫–∞—É–Ω—Ç—ã {sender} –∏ {receiver} —É—Å–ø–µ—à–Ω–æ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω—ã")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–ª–æ–∫–∏—Ä–æ–≤–∫–µ –∞–∫–∫–∞—É–Ω—Ç–æ–≤ {sender} –∏ {receiver}: {e}")

async def enqueue_transaction(redis, tx: dict):
    """–ö–ª–∞–¥–µ–º —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –≤ –æ—á–µ—Ä–µ–¥—å."""
    sender = tx["sender_account"]
    receiver = tx["receiver_account"]
    queue_key = f"queue:{sender}:{receiver}"
    try:
        await redis.rpush(queue_key, json.dumps(tx))
        logger.info(f"üì• –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è {tx['transaction_id']} –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å {queue_key}")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–º–µ—â–µ–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ {tx['transaction_id']} –≤ –æ—á–µ—Ä–µ–¥—å: {e}")

async def dequeue_transaction(redis, sender: str, receiver: str):
    """–í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—é –∏–∑ –æ—á–µ—Ä–µ–¥–∏."""
    queue_key = f"queue:{sender}:{receiver}"
    try:
        tx_data = await redis.lpop(queue_key)
        if tx_data:
            tx = json.loads(tx_data)
            logger.info(f"üì§ –ò–∑–≤–ª–µ—á–µ–Ω–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è {tx['transaction_id']} –∏–∑ –æ—á–µ—Ä–µ–¥–∏ {queue_key}")
            return tx
        else:
            logger.info(f"‚ÑπÔ∏è –û—á–µ—Ä–µ–¥—å {queue_key} –ø—É—Å—Ç–∞")
            return None
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –∏–∑ –æ—á–µ—Ä–µ–¥–∏ {queue_key}: {e}")
        return None

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def handle_transaction(tx: dict, producer, redis, shard_id: int):
    sender = tx["sender_account"]
    receiver = tx["receiver_account"]
    target_topic = f"shard-{shard_id}-validated"

    try:
        logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {tx} –≤ shard {shard_id}")
        await send_with_retry(producer, target_topic, json.dumps(tx).encode("utf-8"))
        orch_sent.inc()
        logger.info(f"‚úÖ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è {tx['transaction_id']} –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –≤ shard {shard_id} –∏ –æ–∂–∏–¥–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {e}")
        await unlock_accounts(redis, sender, receiver)

async def try_next_in_queue(redis, producer, sender: str, receiver: str, shard_id: int):
    next_tx = await dequeue_transaction(redis, sender, receiver)
    if next_tx:
        logger.info(f"üîÅ –°–ª–µ–¥—É—é—â–∞—è —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—ã {sender}-{receiver} –≤ shard {shard_id}")
        await handle_transaction(next_tx, producer, redis, shard_id)
    else:
        await unlock_accounts(redis, sender, receiver)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def handle_confirmation(msg: dict, producer, redis):
    transaction_id = msg["transaction_id"]
    sender = msg["sender_account"]
    receiver = msg["receiver_account"]
    shard_id = get_shard(sender)

    logger.info(f"‚úÖ –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ: —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è ID={transaction_id}, sender={sender}, receiver={receiver}")
    orch_confirmation_received.inc()

    # –ü–µ—Ä–µ—Ö–æ–¥ –æ–±—Ä–∞—Ç–Ω–æ –≤ IDLE –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏
    await try_next_in_queue(redis, producer, sender, receiver, shard_id)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

async def orchestrate():
    consumer = await get_kafka_consumer(topic=TOPIC_API_TO_ORCH, group_id="orchestra-group")
    confirmation_consumer = await get_kafka_consumer(topic=TOPIC_CONFIRMATION, group_id="confirmation-group")
    producer = await get_kafka_producer()
    redis = await aioredis.from_url(REDIS_URL)

    try:
        async def consume_transactions():
            async for msg in consumer:
                try:
                    tx = json.loads(msg.value)
                    sender = tx["sender_account"]
                    receiver = tx["receiver_account"]
                    orch_received.inc()

                    logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–∞ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è: {tx}")

                    shard_id = get_shard(sender)

                    locked = await lock_accounts(redis, sender, receiver)
                    if locked:
                        await handle_transaction(tx, producer, redis, shard_id)
                    else:
                        await enqueue_transaction(redis, tx)
                        orch_queued.inc()
                        logger.info(f"‚è≥ –¢—Ä–∞–Ω–∑–∞–∫—Ü–∏—è {tx['transaction_id']} –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å –¥–ª—è {sender}-{receiver}")

                except Exception as handle_error:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏: {handle_error}")

        async def consume_confirmations():
            async for msg in confirmation_consumer:
                try:
                    confirmation = json.loads(msg.value)
                    await handle_confirmation(confirmation, producer, redis)
                except Exception as confirmation_error:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: {confirmation_error}")

        await asyncio.gather(consume_transactions(), consume_confirmations())

    except Exception as kafka_error:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ Kafka Consumer: {kafka_error}")

    finally:
        await consumer.stop()
        await confirmation_consumer.stop()
        await producer.stop()
        await redis.close()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

if __name__ == "__main__":
    start_http_server(8002)  # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∞–¥—Ä–µ—Å—É :8002/metrics
    asyncio.run(orchestrate())
